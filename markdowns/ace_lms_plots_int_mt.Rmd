---
title: "ACE results, new"
author: "Monica Thieu"
date: "August 12, 2016"
output:
  html_document:
    toc: true
    toc_float: true
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(knitr)
library(ggplot2)
library(tidyr)
library(plyr)
library(dplyr)
library(stringr)
library(lazyeval)
library(outliers)
library(gtools)


source("../R/brt_append.R") # loading in helper functions
source("../R/clean_grade_gender.R")
source("../R/get_outlier_subs.R")
# note to self: now I am extremely concerned about multiple comparisons... I'll do an FDR using n = n_modules * n_varspermodule at some point?
# note: supports flexibility in grade labels, but please beware of over-interpreting gradewise differences when N by grade is low
```

```{r defining printing args READ ME}
# Please set each of these to TRUE or FALSE depending on whether you would like info on the module printed to the summary document.
BRT_PRINT = T
BOX_PRINT = T
FLANK_PRINT = T
SAAT_PRINT = T
SPAN_PRINT = T
BSPAN_PRINT = T
STROOP_PRINT = T
SWITCH_PRINT = T
TNT_PRINT = T
FILTER_PRINT = T

# Please set these to TRUE or FALSE depending on whether you would like outlier checking info or quality control histograms printed for ALL modules or not. Even if these are set to TRUE, they will not print for modules which have been turned off (set as FALSE) in the above block.
OUTLIER_PRINT = TRUE
QC_HIST_PRINT = TRUE

# Please set this to TRUE or FALSE depending on whether you would like ALL continuous x-regressors z-scored. They will always be mean-centered; this just z-scores them by further dividing them by std dev.
Z_SCORE_XREGS = TRUE
```


```{r loading cached -by hand- data}
# load(file = "~/Dropbox/aceR/seacrest_data/clean_data.RData")
# load(file = "~/Documents/ace_large_data/almost_all_preproc_122816.RData")
# load(file = "~/Documents/ace_large_data/almost_all_preproc_050217.RData")
load(file = "~/Documents/ace_large_data/s17_preproc_071717.RData")
proc_demo = proc_s17_all; rm(proc_s17_all)
```

```{r read_chunking, cache=FALSE}
read_chunk("../markdowns/single_module_md.R")
```

```{r school prefixes}
prefixes = c("br", "pe", "la", "se", "ca", "bo", "mh", "mk")
schools = c("Bracher", "Peterson", "Laurelwood", "Seacrest", "Cabrillo", "Bowers", "Most Holy Trinity", "Millikin")
# millenium (mi) currently being excluded by request
```


```{r setting vars for BRT READ ME}
this_task = "BRT"
this_task_long = "BRT"
outlier_vars = c("rt_mean.right", "rt_mean.left")
vars_of_interest = c("rt_mean.dominant", "rt_mean.nondominant")
vars_of_interest_long = c("Mean RT--dominant hand", "Mean RT--non-dominant hand") # nice version for printing in graphs
score_vars = c("rt_mean.overall")
score_formula = NA
```

```{r load brt from proc_demo}
if(this_task == "BRT" & !BRT_PRINT) {} else { # edge case where BRT needs to be evaluated even if no print (and thus header turned off)
  paste0("#", this_task_long) %>%
    asis_output()}
asis_output(print("\n")) # need this for line breaking

grab_module <- function(proc_demo, this_task) {
  d_raw <- proc_demo[[this_task]]
  d_raw <- d_raw[grep(paste0(prefixes, collapse = "|"), d_raw$pid),] # only including data from real Ss (with school-specific ID prefixes)
  d_raw = d_raw %>% filter(time != "0", time != "TIME:", !is.na(grade))
  return (d_raw)
}

d_raw = grab_module(proc_demo, this_task)
```

```{r brt clean outliers}
find_outliers <- function(d_raw, vars) {
  bad_subs = vector("list", length(unique(d_raw$grade)))
  
  for (i in 1:length(vars)) {# for each grade, concatenates vars ACROSS metrics of interest
    for (j in 1:length(unique(d_raw$grade))) {
      # need this to verify that there are >2 valid data pts in this grade level to do the outlier test
      these_vals_temp = with(d_raw, get(vars[i])[grade == unique(grade)[j] & !is.na(get(vars[i]))])
      if(length(these_vals_temp) > 2) {
        these_bad_subs = d_raw %>%
          filter(grade == unique(grade)[j]) %>%
          with(
            get_outlier_subs(get(vars[i]), pid))
      } else {these_bad_subs = NULL}
      if(!is.null(these_bad_subs)) {bad_subs[[j]] = c(bad_subs[[j]], these_bad_subs)}
    }
  }
  return (unlist(bad_subs))
}

bad_subs = find_outliers(d_raw, outlier_vars)
d <- d_raw %>%
  filter(!(pid %in% bad_subs))
```

```{r brt clean short rts, eval=BRT_PRINT}
find_short_rts <- function(d, vars) {
  short_rt_subs = NULL
  
  for (i in 1:min(c(length(vars), 2))) { # if there are 3 vars of interest the 3rd one is cost, which should NOT be counted for this
    short_rt_subs = c(short_rt_subs, d$pid[d[, vars[i]] < 150])
  }
  short_rt_subs = short_rt_subs[!is.na(short_rt_subs)]
  return (short_rt_subs)
}

short_rt_subs = find_short_rts(d, outlier_vars)
d <- d %>%
  filter(!(pid %in% short_rt_subs))

asis_output("##subs w/ short RTs on ANY var of interest(< 150 ms)")
asis_output(print("\n"))
print(short_rt_subs)

```

```{r brt preproc}
# always run this irrespective of BRT_PRINT
d <- d %>%
  clean_grade_gender()

if ("handedness" %in% names(d)) {
  d <- d %>%
    mutate(rt_mean.dominant = if_else(handedness == "R", rt_mean.right, rt_mean.left, NA_real_),
           rt_mean.nondominant = if_else(handedness == "L", rt_mean.right, rt_mean.left, NA_real_),
           acc_mean.dominant = if_else(handedness == "R", acc_mean.right, acc_mean.left, NA_real_),
           acc_mean.nondominant = if_else(handedness == "L", acc_mean.right, acc_mean.left, NA_real_))
} else { # if handedness not provided, assume all R handed (for purposes of actually running analysis)
  d <- d %>%
    mutate(rt_mean.dominant = rt_mean.right,
           rt_mean.nondominant = rt_mean.left,
           acc_mean.dominant = acc_mean.right,
           acc_mean.nondominant = acc_mean.left)
}


asis_output("##n by grade and gender")
asis_output(print("\n"))
table(d$grade_label, d$gender)
```

```{r caching brt for appending to subsequent modules}
brt <- d
```

```{r ref.label="score_feedback_means", eval=BRT_PRINT}
```

```{r ref.label="qc_graphs", eval=(BRT_PRINT & QC_HIST_PRINT)}
```

```{r brt lms, eval=BRT_PRINT}
# edge case here where BRT can't be regressed against itself
asis_output("##regressions")
asis_output(print("\n"))
paste("###", vars_of_interest_long[1], sep = "") %>%
  asis_output()
d %>%
  with(summary(lm(get(vars_of_interest[1]) ~ grade * gender)))

asis_output(print("\n"))
paste("###", vars_of_interest_long[2], sep = "") %>%
  asis_output()
d %>%
  with(summary(lm(get(vars_of_interest[2]) ~ grade * gender)))
```

```{r ref.label="graphs", eval=BRT_PRINT}
```

```{r brt lms by acc, eval=BRT_PRINT}
vars_of_interest = c("acc_mean.dominant", "acc_mean.nondominant")
vars_of_interest_long = c("Accuracy--dominant hand", "Accuracy--non-dominant hand") 

asis_output("##regressions")
asis_output(print("\n"))
paste("###", vars_of_interest_long[1], sep = "") %>%
  asis_output()
d %>%
  with(summary(lm(get(vars_of_interest[1]) ~ grade * gender)))

asis_output(print("\n"))
paste("###", vars_of_interest_long[2], sep = "") %>%
  asis_output()
d %>%
  with(summary(lm(get(vars_of_interest[2]) ~ grade * gender)))
```

```{r ref.label="graphs", eval=BRT_PRINT}
```

```{r setting vars for boxed READ ME}
this_task = "BOXED"
this_task_long = "Boxed"
outlier_vars = "rt_mean.overall"
vars_of_interest = c("rt_mean.feature", "rt_mean.conjunction", "rt_mean.cost")
vars_of_interest_long = c("Mean overall RT, feature trials", "Mean overall RT, conjunction trials", "Mean cost of conjunction on RT (conj - feat)") # nice version for printing in graphs
vars_of_interest_acc = list(c("rt_mean.correct.feature", "rt_mean.incorrect.feature"),
                            c("rt_mean.correct.conjunction", "rt_mean.incorrect.conjunction"),
                            c("rt_mean.correct.cost", "rt_mean.incorrect.cost"))
vars_of_interest_acc_long = list(c("Mean RT--feature trials, correct press", "Mean RT--feature trials, incorrect press"),
                                 c("Mean RT--conjunction trials, correct press", "Mean RT--conjunction trials, incorrect press"),
                                 c("Mean cost (conj - feat) on RT--correct press", "Mean cost (conj - feat) on RT--incorrect press"))
score_vars = c("rt_mean.conjunction_4", "rt_mean.conjunction_12")
score_formula = "fraction"
brt_rt_var = "brt_rt_mean.dominant"
```

```{r boxed load from proc_demo, eval=BOX_PRINT}
d_raw = grab_module(proc_demo, this_task)
```

```{r boxed remove outliers, eval=BOX_PRINT}
bad_subs = find_outliers(d_raw, outlier_vars)
d <- d_raw %>%
  filter(!(pid %in% bad_subs))
```

```{r boxed remove short rts, eval=BOX_PRINT}
short_rt_subs = find_short_rts(d, outlier_vars)
d <- d %>%
  filter(!(pid %in% short_rt_subs))
```

```{r boxed preproc, eval=BOX_PRINT}
d <- d %>%
  brt_append(brt) %>%
  clean_grade_gender()

# NB: gender is effect coded female: -1 male: 1
# such that a POSITIVE beta estimate for RT change by gender indicates that FEMALES are faster (RT for males HIGHER)

asis_output("##n by grade and gender")
asis_output(print("\n"))
table(d$grade_label, d$gender)
```

```{r boxed extra preproc, eval=BOX_PRINT}
d <- d %>%
  mutate(rt_mean.conjunction = (rt_mean.conjunction_12 + rt_mean.conjunction_4) / 2,
         rt_mean.feature = (rt_mean.feature_12 + rt_mean.feature_4) / 2,
         rt_mean.cost = rt_mean.conjunction - rt_mean.feature,
         rt_mean.correct.conjunction = (rt_mean.correct.conjunction_12 + rt_mean.correct.conjunction_4) / 2,
         rt_mean.correct.feature = (rt_mean.correct.feature_12 + rt_mean.correct.feature_4) / 2,
         rt_mean.correct.cost = rt_mean.correct.conjunction - rt_mean.correct.feature,
         rt_mean.incorrect.conjunction = (rt_mean.incorrect.conjunction_12 + rt_mean.incorrect.conjunction_4) / 2,
         rt_mean.incorrect.feature = (rt_mean.incorrect.feature_12 + rt_mean.incorrect.feature_4) / 2,
         rt_mean.incorrect.cost = rt_mean.incorrect.conjunction - rt_mean.incorrect.feature)
```

```{r ref.label="score_feedback_means", eval=BOX_PRINT}
```

```{r ref.label="qc_graphs", eval=(BOX_PRINT & QC_HIST_PRINT)}
```

```{r ref.label="residual_rt_graphs", eval=(BOX_PRINT & QC_HIST_PRINT)}
```

```{r ref.label="lms", eval=BOX_PRINT}
```

```{r ref.label="lms_by_acc", eval=BOX_PRINT}
```

```{r ref.label="graphs", eval=BOX_PRINT}
```

```{r ref.label="graphs_by_acc", eval=BOX_PRINT}
```

```{r boxed resetting vars of interest to acc, eval=BOX_PRINT}
d <- d %>%
  mutate(acc_mean.feature = (acc_mean.feature_4 + acc_mean.feature_12) / 2,
         acc_mean.conjunction = (acc_mean.conjunction_4 + acc_mean.conjunction_12) / 2,
         acc_mean.cost = acc_mean.conjunction - acc_mean.feature,
         acc_mean.early.feature = (acc_mean.early.feature_4 + acc_mean.early.feature_12) / 2,
         acc_mean.early.conjunction = (acc_mean.early.conjunction_4 + acc_mean.early.conjunction_12) / 2,
         acc_mean.early.cost = acc_mean.early.conjunction - acc_mean.early.feature,
         acc_mean.late.feature = (acc_mean.late.feature_4 + acc_mean.late.feature_12) / 2,
         acc_mean.late.conjunction = (acc_mean.late.conjunction_4 + acc_mean.late.conjunction_12) / 2,
         acc_mean.late.cost = acc_mean.late.conjunction - acc_mean.late.feature)

boxed = d

vars_of_interest = c("acc_mean.feature", "acc_mean.conjunction", "acc_mean.cost")
vars_of_interest_long = c("Accuracy, feature trials", "Accuracy, conjunction trials", "Accuracy cost (conj - feat)") # nice version for printing in graphs
vars_of_interest_acc = list(c("acc_mean.late.feature", "acc_mean.early.feature"),
                            c("acc_mean.late.conjunction", "acc_mean.early.conjunction"),
                            c("acc_mean.late.cost", "acc_mean.early.cost"))
vars_of_interest_acc_long = list(c("Accuracy--feature trials, late press", "Accuracy--feature trials, early press"),
                                 c("Accuracy--conjunction trials, late press", "Accuracy--conjunction trials, early press"),
                                 c("Mean cost (conj - feat) on accuracy--late press", "Mean cost (conj - feat) on accuracy--early press"))
```

```{r ref.label="lms", eval=BOX_PRINT}
```

```{r ref.label="lms_by_acc", eval=BOX_PRINT}
```

```{r ref.label="graphs", eval=BOX_PRINT}
```

```{r ref.label="graphs_by_acc", eval=BOX_PRINT}
```

```{r setting vars for flanker READ ME}
this_task = "FLANKER"
this_task_long = "Flanker"
vars_of_interest = c("rt_mean.congruent","rt_mean.incongruent","rt_mean.cost")
vars_of_interest_long = c("Mean RT--congruent trials", "Mean RT--incongruent trials", "Mean cost of incongruence on RT") # nice version for printing in graphs
vars_of_interest_acc = list(c("rt_mean.correct.congruent", "rt_mean.incorrect.congruent"),
                            c("rt_mean.correct.incongruent", "rt_mean.incorrect.incongruent"),
                            c("rt_mean.correct.cost", "rt_mean.incorrect.cost"))
vars_of_interest_acc_long = list(c("Mean RT--congruent trials, correct press", "Mean RT--congruent trials, incorrect press"),
                                 c("Mean RT--incongruent trials, correct press", "Mean RT--incongruent trials, incorrect press"),
                                 c("Mean cost of incongruence on RT--correct press", "Mean cost of incongruence on RT--incorrect press"))
score_vars = c("rt_mean.congruent", "rt_mean.incongruent")
score_formula = "fraction"
brt_rt_var = "brt_rt_mean.overall"
```

```{r flanker load from proc_demo, eval=FLANK_PRINT}
d_raw = grab_module(proc_demo, this_task)
```

```{r flanker remove outliers, eval=FLANK_PRINT}
bad_subs = find_outliers(d_raw, vars_of_interest)
d <- d_raw %>%
  filter(!(pid %in% bad_subs))
```

```{r flanker remove short rts, eval=FLANK_PRINT}
short_rt_subs = find_short_rts(d, vars_of_interest)
d <- d %>%
  filter(!(pid %in% short_rt_subs))
```

```{r flanker preproc, eval=FLANK_PRINT}
d <- d %>%
  brt_append(brt) %>%
  clean_grade_gender()

flanker = d

asis_output("##n by grade and gender")
asis_output(print("\n"))
table(d$grade_label, d$gender)
```


```{r ref.label="score_feedback_means", eval=FLANK_PRINT}
```

```{r ref.label="qc_graphs", eval=(FLANK_PRINT & QC_HIST_PRINT)}
```

```{r ref.label="residual_rt_graphs", eval=(FLANK_PRINT & QC_HIST_PRINT)}
```

```{r ref.label="lms", eval=FLANK_PRINT}
```

```{r ref.label="lms_by_acc", eval=FLANK_PRINT}
```

```{r ref.label="graphs", eval=FLANK_PRINT}
```

```{r ref.label="graphs_by_acc", eval=FLANK_PRINT}
```

```{r flanker resetting vars of interest to acc, eval=FLANK_PRINT}
vars_of_interest = c("acc_mean.congruent", "acc_mean.incongruent", "acc_mean.cost")
vars_of_interest_long = c("Accuracy, congruent trials", "Accuracy, incongruent trials", "Accuracy cost (incong - cong)") # nice version for printing in graphs
```

```{r ref.label="lms", eval=FLANK_PRINT}
```

```{r ref.label="graphs", eval=FLANK_PRINT}
```

```{r setting vars for saat READ ME}
this_task = "SAAT"
this_task_long = "SAAT"
vars_of_interest = c("rt_mean.correct.sustained","rt_mean.correct.impulsive")
vars_of_interest_long = c("Mean hit RT--sustained trials", "Mean hit RT--impulsive trials") # nice version for printing in graphs
vars_of_interest_acc = list(c("rt_mean.correct.sustained", "rt_mean.incorrect.sustained"),
                            c("rt_mean.correct.impulsive", "rt_mean.incorrect.impulsive"))
vars_of_interest_acc_long = list(c("Mean RT--sustained trials, correct press", "Mean RT--sustained trials, incorrect press"),
                                 c("Mean RT--impulsive trials, correct press", "Mean RT--impulsive trials, incorrect press"))
score_vars = vars_of_interest
score_formula = NA
brt_rt_var = "brt_rt_mean.overall"
```

```{r saat load from proc_demo, eval=SAAT_PRINT}
d_raw = grab_module(proc_demo, this_task)
```

```{r saat remove outliers, eval=SAAT_PRINT}
bad_subs = find_outliers(d_raw, vars_of_interest)
d <- d_raw %>%
  filter(!(pid %in% bad_subs))
```

```{r saat remove short rts, eval=FALSE}
short_rt_subs = find_short_rts(d, vars_of_interest)
d <- d %>%
  filter(!(pid %in% short_rt_subs))
```

```{r saat preproc, eval=SAAT_PRINT}
d <- d %>%
  brt_append(brt) %>%
  clean_grade_gender()

# select(-contains(".."), -ends_with(".y"), -(acc_median.sustained.x:acc_mean.overall.x))
# names(d)[grepl(".x", names(d))] = str_sub(names(d)[grepl(".x", names(d))], end = -3)
d <- d %>%
  mutate(acc_mean.1.impulsive = if_else(acc_mean.1.impulsive == 1, .9999, acc_mean.1.impulsive),
         acc_mean.1.sustained = if_else(acc_mean.1.sustained == 1, .9999, acc_mean.1.sustained),
         acc_mean.0.impulsive = if_else(acc_mean.0.impulsive == 1, .9999, acc_mean.0.impulsive),
         acc_mean.0.sustained = if_else(acc_mean.0.sustained == 1, .9999, acc_mean.0.sustained),
         acc_mean.1.impulsive = if_else(acc_mean.1.impulsive == 0, .0001, acc_mean.1.impulsive),
         acc_mean.1.sustained = if_else(acc_mean.1.sustained == 0, .0001, acc_mean.1.sustained),
         acc_mean.0.impulsive = if_else(acc_mean.0.impulsive == 0, .0001, acc_mean.0.impulsive),
         acc_mean.0.sustained = if_else(acc_mean.0.sustained == 0, .0001, acc_mean.0.sustained),
         dprime.impulsive = qnorm(acc_mean.1.impulsive) - qnorm(1 - acc_mean.0.impulsive),
         dprime.sustained = qnorm(acc_mean.1.sustained) - qnorm(1 - acc_mean.0.sustained)) # dumb snodgrassing

# as of 1/10/17: the aceR pipeline now switches the imp/sus labels! whee
# 1 - acc_mean.0 roughly yields FA rate (true NRs get counted as CRs??), since acc_mean.0 is CR rate

saat = d

asis_output("##n by grade and gender")
asis_output(print("\n"))
table(d$grade_label, d$gender)
```

```{r ref.label="score_feedback_means", eval=SAAT_PRINT}
```

```{r ref.label="qc_graphs", eval=(SAAT_PRINT & QC_HIST_PRINT)}
```

```{r ref.label="residual_rt_graphs", eval=(SAAT_PRINT & QC_HIST_PRINT)}
```

```{r ref.label="lms", eval=SAAT_PRINT}
```

```{r ref.label="lms_by_acc", eval=SAAT_PRINT}
```

```{r ref.label="graphs", eval=SAAT_PRINT}
```

```{r ref.label="graphs_by_acc", eval=SAAT_PRINT}
```

```{r saat resetting vars of interest to dprime, eval=SAAT_PRINT}
vars_of_interest = c("dprime.sustained", "dprime.impulsive")
vars_of_interest_long = c("d', sustained trials", "d', impulsive trials")
```

```{r ref.label="lms", eval=SAAT_PRINT}
```

```{r ref.label="graphs", eval=SAAT_PRINT}
```

```{r saat resetting vars of interest to raw acc, eval=SAAT_PRINT}
vars_of_interest = c("acc_mean.sustained", "acc_mean.impulsive")
vars_of_interest_long = c("Accuracy (hits + CRs), sustained trials", "Accuracy (hits + CRs), impulsive trials")
```

```{r ref.label="lms", eval=SAAT_PRINT}
```

```{r ref.label="graphs", eval=SAAT_PRINT}
```

```{r setting vars for span READ ME}
this_task = "SPATIALSPAN"
this_task_long = "Spatial span"
vars_of_interest = "object_count_span.overall"
vars_of_interest_long = "Overall span (obj count)" # nice version for printing in graphs
# NOT running the outlier check on the object span metric... I think I broke grubbs.test
score_vars = vars_of_interest
score_formula = NA
```

```{r span load from proc_demo, eval=SPAN_PRINT}
d_raw = grab_module(proc_demo, this_task)
```

```{r span preproc, eval=SPAN_PRINT}
d <- d_raw %>%
  brt_append(brt) %>%
  clean_grade_gender()

span = d

asis_output("##n by grade and gender")
asis_output(print("\n"))
table(d$grade_label, d$gender)
```


```{r ref.label="score_feedback_means", eval=SPAN_PRINT}
```

```{r ref.label="qc_graphs", eval=(SPAN_PRINT & QC_HIST_PRINT)}
```

```{r ref.label="lms_no_brt", eval=SPAN_PRINT}
```

```{r ref.label="graphs", eval=SPAN_PRINT}
```

```{r setting vars for backward span READ ME}
this_task = "BACKWARDSSPATIALSPAN"
this_task_long = "Backward spatial span"
vars_of_interest = "object_count_span.overall"
vars_of_interest_long = "Overall span (obj count)" # nice version for printing in graphs
# NOT running the outlier check on the object span metric... I think I broke grubbs.test
score_vars = vars_of_interest
score_formula = NA
```

```{r bspan load from proc_demo, eval=BSPAN_PRINT}
d_raw = grab_module(proc_demo, this_task)
```

```{r bspan preproc, eval=BSPAN_PRINT}
d <- d_raw %>%
  brt_append(brt) %>%
  clean_grade_gender()

bspan = d

asis_output("##n by grade and gender")
asis_output(print("\n"))
table(d$grade_label, d$gender)
```

```{r ref.label="score_feedback_means", eval=BSPAN_PRINT}
```

```{r ref.label="qc_graphs", eval=(BSPAN_PRINT & QC_HIST_PRINT)}
```

```{r ref.label="lms_no_brt", eval=BSPAN_PRINT}
```

```{r ref.label="graphs", eval=BSPAN_PRINT}
```

```{r setting vars for stroop READ ME}
this_task = "STROOP"
this_task_long = "Stroop task"
vars_of_interest = c("rt_mean.congruent","rt_mean.incongruent","rt_mean.cost")
vars_of_interest_long = c("Mean RT--congruent trials", "Mean RT--incongruent trials", "Mean cost of incongruence on RT") # nice version for printing in graphs
vars_of_interest_acc = list(c("rt_mean.correct.congruent", "rt_mean.incorrect.congruent"),
                            c("rt_mean.correct.incongruent", "rt_mean.incorrect.incongruent"),
                            c("rt_mean.correct.cost", "rt_mean.incorrect.cost"))
vars_of_interest_acc_long = list(c("Mean RT--congruent trials, correct press", "Mean RT--congruent trials, incorrect press"),
                                 c("Mean RT--incongruent trials, correct press", "Mean RT--incongruent trials, incorrect press"),
                                 c("Mean cost of incongruence on RT--correct press", "Mean cost of incongruence on RT--incorrect press"))
score_vars = c("rt_mean.congruent", "rt_mean.incongruent")
score_formula = "fraction"
brt_rt_var = "brt_rt_mean.overall"
```

```{r stroop load from proc_demo, eval=STROOP_PRINT}
d_raw = grab_module(proc_demo, this_task)
```

```{r stroop remove outliers, eval=STROOP_PRINT}
bad_subs = find_outliers(d_raw, vars_of_interest)
d <- d_raw %>%
  filter(!(pid %in% bad_subs))
```

```{r stroop remove short rts, eval=STROOP_PRINT}
short_rt_subs = find_short_rts(d, vars_of_interest)
d <- d %>%
  filter(!(pid %in% short_rt_subs))
```

```{r stroop preproc, eval=STROOP_PRINT}
d <- d %>%
  brt_append(brt) %>%
  clean_grade_gender()

stroop = d

asis_output("##n by grade and gender")
asis_output(print("\n"))
table(d$grade_label, d$gender)
```

```{r ref.label="score_feedback_means", eval=STROOP_PRINT}
```

```{r ref.label="qc_graphs", eval=(STROOP_PRINT & QC_HIST_PRINT)}
```

```{r ref.label="residual_rt_graphs", eval=(STROOP_PRINT & QC_HIST_PRINT)}
```

```{r ref.label="lms", eval=STROOP_PRINT}
```

```{r ref.label="lms_by_acc", eval=STROOP_PRINT}
```

```{r ref.label="graphs", eval=STROOP_PRINT}
```

```{r ref.label="graphs_by_acc", eval=STROOP_PRINT}
```

```{r stroop resetting vars of interest to acc, eval=STROOP_PRINT}
vars_of_interest = c("acc_mean.congruent", "acc_mean.incongruent", "acc_mean.cost")
vars_of_interest_long = c("Accuracy, congruent trials", "Accuracy, incongruent trials", "Accuracy cost (incong - cong)") # nice version for printing in graphs
```

```{r ref.label="lms", eval=STROOP_PRINT}
```

```{r ref.label="graphs", eval=STROOP_PRINT}
```

```{r setting vars for task switch READ ME}
this_task = "TASKSWITCH"
this_task_long = "Task switch"
vars_of_interest = c("rt_mean.stay","rt_mean.switch", "rt_mean.cost")
vars_of_interest_long = c("Mean RT--stay trials", "Mean RT--switch trials", "Mean cost on RT (switch - stay)") # nice version for printing in graphs
vars_of_interest_acc = list(c("rt_mean.correct.stay", "rt_mean.incorrect.stay"),
                            c("rt_mean.correct.switch", "rt_mean.incorrect.switch"),
                            c("rt_mean.correct.cost", "rt_mean.incorrect.cost"))
vars_of_interest_acc_long = list(c("Mean RT--stay trials, correct press", "Mean RT--stay trials, incorrect press"),
                                 c("Mean RT--switch trials, correct press", "Mean RT--switch trials, incorrect press"),
                                 c("Mean cost of switching on RT--correct press", "Mean cost of switching on RT--incorrect press"))
score_vars = vars_of_interest 
score_formula = NA
brt_rt_var = "brt_rt_mean.overall"
```

```{r switch load from proc_demo, eval=SWITCH_PRINT}
d_raw = grab_module(proc_demo, this_task)
```

```{r switch remove outliers, eval=SWITCH_PRINT}
bad_subs = find_outliers(d_raw, vars_of_interest)
d <- d_raw %>%
  filter(!(pid %in% bad_subs))
```

```{r switch remove short rts, eval=SWITCH_PRINT}
short_rt_subs = find_short_rts(d, vars_of_interest)
d <- d %>%
  filter(!(pid %in% short_rt_subs))
```

```{r switch preproc, eval=SWITCH_PRINT}
d <- d %>%
  brt_append(brt) %>%
  clean_grade_gender()

switch = d

asis_output("##n by grade and gender")
asis_output(print("\n"))
table(d$grade_label, d$gender)
```


```{r ref.label="score_feedback_means", eval=SWITCH_PRINT}
```

```{r ref.label="qc_graphs", eval=(SWITCH_PRINT & QC_HIST_PRINT)}
```

```{r ref.label="residual_rt_graphs", eval=(SWITCH_PRINT & QC_HIST_PRINT)}
```

```{r ref.label="lms", eval=SWITCH_PRINT}
```

```{r ref.label="lms_by_acc", eval=SWITCH_PRINT}
```

```{r ref.label="graphs", eval=SWITCH_PRINT}
```

```{r ref.label="graphs_by_acc", eval=SWITCH_PRINT}
```

```{r switch resetting vars of interest to acc, eval=SWITCH_PRINT}
vars_of_interest = c("acc_mean.switch", "acc_mean.stay", "acc_mean.cost")
vars_of_interest_long = c("Accuracy, switch trials", "Accuracy, stay trials", "Accuracy cost (switch - stay)") # nice version for printing in graphs
```

```{r ref.label="lms", eval=SWITCH_PRINT}
```

```{r ref.label="graphs", eval=SWITCH_PRINT}
```

```{r setting vars for tap n trace READ ME}
this_task = "TNT"
this_task_long = "Tap and trace"
vars_of_interest = c("rt_mean.tap_only","rt_mean.tap_trace", "rt_mean.cost")
vars_of_interest_long = c("Mean RT--tap only trials", "Mean RT--tap and trace trials", "Mean cost of dual task on RT (tap&trace - tap only)") # nice version for printing in graphs
vars_of_interest_acc = list(c("rt_mean.correct.tap_only", "rt_mean.incorrect.tap_only"),
                            c("rt_mean.correct.tap_trace", "rt_mean.incorrect.tap_trace"),
                            c("rt_mean.correct.cost", "rt_mean.incorrect.cost"))
vars_of_interest_acc_long = list(c("Mean RT--tap only trials, correct press", "Mean RT--tap only trials, incorrect press"),
                                 c("Mean RT--tap & trace trials, correct press", "Mean RT--tap & trace trials, incorrect press"),
                                 c("Mean cost of dual task on RT--correct press", "Mean cost of dual task on RT--incorrect press"))
score_vars = vars_of_interest
score_formula = NA
brt_rt_var = "brt_rt_mean.nondominant"
```


```{r tnt load from proc_demo, eval=TNT_PRINT}
d_raw = grab_module(proc_demo, this_task)
```

```{r tnt remove outliers, eval=TNT_PRINT}
bad_subs = find_outliers(d_raw, vars_of_interest)
d <- d_raw %>%
  filter(!(pid %in% bad_subs))
```

```{r tnt remove short rts, eval=TNT_PRINT}
short_rt_subs = find_short_rts(d, vars_of_interest)
d <- d %>%
  filter(!(pid %in% short_rt_subs))
```

```{r tnt preproc, eval=TNT_PRINT}
d <- d %>%
  brt_append(brt) %>%
  clean_grade_gender()

tnt = d

asis_output("##n by grade and gender")
asis_output(print("\n"))
table(d$grade_label, d$gender)
```


```{r ref.label="score_feedback_means", eval=TNT_PRINT}
```

```{r ref.label="qc_graphs", eval=(TNT_PRINT & QC_HIST_PRINT)}
```

```{r ref.label="residual_rt_graphs", eval=(TNT_PRINT & QC_HIST_PRINT)}
```

```{r ref.label="lms", eval=TNT_PRINT}
```

```{r ref.label="lms_by_acc", eval=TNT_PRINT}
```

```{r ref.label="graphs", eval=TNT_PRINT}
```

```{r ref.label="graphs_by_acc", eval=TNT_PRINT}
```

```{r setting vars for filter READ ME}
this_task = "FILTER"
this_task_long = "Vogel filtering"
vars_of_interest = c("k.2", "k.4")
vars_of_interest_long = c("k = 2 targets * (Hit - FA)", "k = 4 targets * (Hit - FA)") # nice version for printing in graphs
score_vars = vars_of_interest
score_formula = NA
brt_rt_var = "brt_rt_mean.dominant"
```

```{r filter load from proc_demo, eval=FILTER_PRINT}
d_raw = grab_module(proc_demo, this_task)
```

```{r filter preproc, eval=FILTER_PRINT}
d <- d_raw %>%
  brt_append(brt) %>%
  clean_grade_gender() %>%
  mutate(rt_mean.2 = (rt_mean.correct.2 + rt_mean.incorrect.2) / 2,
         rt_mean.4 = (rt_mean.correct.4 + rt_mean.incorrect.4) / 2)

filter = d

asis_output("##n by grade and gender")
asis_output(print("\n"))
table(d$grade_label, d$gender)
```


```{r ref.label="score_feedback_means", eval=FILTER_PRINT}
```

```{r ref.label="qc_graphs", eval=(FILTER_PRINT & QC_HIST_PRINT)}
```

```{r ref.label="residual_rt_graphs", eval=(FILTER_PRINT & QC_HIST_PRINT)}
```

```{r filter lms, eval=FILTER_PRINT}
# this one has to be special because we're also regressing by distractor number which doesn't apply for other modules
asis_output("##regressions")
asis_output(print("\n"))
paste("###", vars_of_interest_long[1], sep = "") %>%
  asis_output()
d %>%
  with(summary(lm(get(vars_of_interest[1]) ~ grade * gender * distractors)))

asis_output(print("\n"))
paste("###", vars_of_interest_long[2], sep = "") %>%
  asis_output() # dumb: they have to be in two separate if statements to get the heading to render
d %>%
  with(summary(lm(get(vars_of_interest[2]) ~ grade * gender * distractors)))
```

```{r filter graphs, eval=FILTER_PRINT}
# again special because need to plot by distractor number
asis_output("##graphs")
asis_output(print("\n"))
paste("###", vars_of_interest_long[1], sep = "") %>%
  asis_output()

d_plot <- d %>%
  group_by(grade_label, distractors) %>%
  summarize(k.2.mean = mean(k.2, na.rm = T),
            k.4.mean = mean(k.4, na.rm = T),
            k.2.se = sd(k.2, na.rm = T)/sqrt(length(!is.na(k.2))),
            k.4.se = sd(k.4, na.rm = T)/sqrt(!is.na(length(k.4))))

d_plot %>%
  ggplot(aes(x = distractors, y = get(paste0(vars_of_interest[1], ".mean")), color = factor(grade_label))) +
  geom_point() +
  geom_line() +
  geom_errorbar(aes(ymin = get(paste0(vars_of_interest[1], ".mean")) - get(paste0(vars_of_interest[1], ".se")),
                    ymax = get(paste0(vars_of_interest[1], ".mean")) + get(paste0(vars_of_interest[1], ".se")),
                    width = 0.5)) +
  labs(y = vars_of_interest_long[1]) +
  guides(color = guide_legend(title = "Grade"))

asis_output(print("\n"))
paste("###", vars_of_interest_long[2], sep = "") %>%
  asis_output()

d_plot %>%
  ggplot(aes(x = distractors, y = get(paste0(vars_of_interest[2], ".mean")), color = factor(grade_label))) +
  geom_point() +
  geom_line() +
  geom_errorbar(aes(ymin = get(paste0(vars_of_interest[2], ".mean")) - get(paste0(vars_of_interest[2], ".se")),
                    ymax = get(paste0(vars_of_interest[2], ".mean")) + get(paste0(vars_of_interest[2], ".se")),
                    width = 0.5)) +
  labs(y = vars_of_interest_long[2]) +
  guides(color = guide_legend(title = "Grade"))
```

```{r filter resetting vars of interest to rt, eval=FILTER_PRINT}
vars_of_interest = c("rt_mean.2", "rt_mean.4")
vars_of_interest_long = c("Mean RT, 2 targets", "Mean RT, 4 targets")
vars_of_interest_acc = list(c("rt_mean.correct.2", "rt_mean.incorrect.2"),
                            c("rt_mean.correct.4", "rt_mean.incorrect.4"))
vars_of_interest_acc_long = list(c("Mean RT--2 targets trials, correct press", "Mean RT--2 targets trials, incorrect press"),
                                 c("Mean RT--4 targets trials, correct press", "Mean RT--4 targets trials, incorrect press"))
```

```{r ref.label="lms", eval=FILTER_PRINT}
```

```{r ref.label="graphs", eval=FILTER_PRINT}
```

```{r ref.label="lms_by_acc", eval=FILTER_PRINT}
```

```{r ref.label="graphs_by_acc", eval=FILTER_PRINT}
```

```{r cfa scratch, eval = FALSE}
cfa_model_3 = ' shift =~ switch_rt_mean.cost + tnt_rt_mean.cost
                update =~ bspan_rt_mean.correct
                inhibit =~ stroop_rt_mean.cost + flanker_rt_mean.cost + saat_rt_mean.correct.sustained '

cfa_model_sep = ' shift =~ switch_rt_mean.cost + tnt_rt_mean.cost
                  update =~ bspan_rt_mean.correct
                  inhibit =~ switch_rt_mean.cost + tnt_rt_mean.cost + bspan_rt_mean.correct + stroop_rt_mean.cost + flanker_rt_mean.cost + saat_rt_mean.correct.sustained
                  shift ~ 1 
                  update ~ 1 
                  inhibit ~ 1 '
```

